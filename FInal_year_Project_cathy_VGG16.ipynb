{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNInwNuTXkasxFACa7oUHjF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Catherinelapir/Final-year-project-image-segmentation-model/blob/main/FInal_year_Project_cathy_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlRrZFen8rSC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, keras\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "import natsort"
      ],
      "metadata": {
        "id": "P3i4MwzL9Cr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator, img_to_array, array_to_img"
      ],
      "metadata": {
        "id": "dD1sdcM59L-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model, Sequential"
      ],
      "metadata": {
        "id": "Mx9a3G099Rt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir1 = \"/content/drive/MyDrive/image_copy/image_copy1/\"\n",
        "combined_mask_dir1=\"/content/drive/MyDrive/mask_copy/content/combined_masks/\"\n",
        "\n",
        "input_dir2 = \"/content/drive/MyDrive/image_copy/image_copy1_augmented_vertically/\"\n",
        "combined_mask_dir2 = \"/content/drive/MyDrive/mask_copy/content/combined_masks_augmented_vertically/\"\n",
        "\n",
        "input_dir4 = \"/content/drive/MyDrive/image_copy/augmented_image_rotated/\"\n",
        "combined_mask_dir4 = \"/content/drive/MyDrive/mask_copy/content/augmented_rotated_masks/\"\n",
        "\n",
        "input_dir5 = \"/content/drive/MyDrive/image_copy/augmented_image_zoom/\"\n",
        "combined_mask_dir5 = \"/content/drive/MyDrive/mask_copy/content/augmented_mask_zoomed/\"\n",
        "\n",
        "input_dir6 = \"/content/drive/MyDrive/image_copy/augmented_image_shift_width/\"\n",
        "combined_mask_dir6 = \"/content/drive/MyDrive/mask_copy/content/augmented_mask_width_shifted/\"\n"
      ],
      "metadata": {
        "id": "sFZwnc6Y9WR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir_img = \"/content/drive/MyDrive/image_copy/image_test/\"\n",
        "test_dir_mask = \"/content/drive/MyDrive/mask_copy/content/mask_test/\""
      ],
      "metadata": {
        "id": "Ol_Y66099cRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_test_img_paths = natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(test_dir_img, fname)\n",
        "        for fname in os.listdir(test_dir_img)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_test_img_paths[16:20]"
      ],
      "metadata": {
        "id": "zrH8pO5p9jmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_test_mask_paths = natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(test_dir_mask, fname)\n",
        "        for fname in os.listdir(test_dir_mask)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_test_mask_paths[16:20]"
      ],
      "metadata": {
        "id": "GllYrV9B9mXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img_paths1 = natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(input_dir1, fname)\n",
        "        for fname in os.listdir(input_dir1)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_img_paths1[16:20]"
      ],
      "metadata": {
        "id": "mVVaUQMk9rGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_mask_paths1 =natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(combined_mask_dir1, fname)\n",
        "        for fname in os.listdir(combined_mask_dir1)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "combined_mask_paths1[16:20]"
      ],
      "metadata": {
        "id": "dG4j7a_C9w1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img_paths2 = natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(input_dir2, fname)\n",
        "        for fname in os.listdir(input_dir2)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_img_paths2[16:20]"
      ],
      "metadata": {
        "id": "UlehqnK294zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_mask_paths2 = natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(combined_mask_dir2, fname)\n",
        "        for fname in os.listdir(combined_mask_dir2)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "combined_mask_paths2[16:20]"
      ],
      "metadata": {
        "id": "XdufAHck96ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img_paths4 = natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(input_dir4, fname)\n",
        "        for fname in os.listdir(input_dir4)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_img_paths4[16:20]"
      ],
      "metadata": {
        "id": "z0Jzt9W89--R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_mask_paths4 = natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(combined_mask_dir4, fname)\n",
        "        for fname in os.listdir(combined_mask_dir4)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "combined_mask_paths4[16:20]"
      ],
      "metadata": {
        "id": "3Tk8Vt_2-E7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img_paths5 = natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(input_dir5, fname)\n",
        "        for fname in os.listdir(input_dir5)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_img_paths5[16:20]"
      ],
      "metadata": {
        "id": "GbPRVkEb-LvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_mask_paths5 = natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(combined_mask_dir5, fname)\n",
        "        for fname in os.listdir(combined_mask_dir5)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "combined_mask_paths5[16:20]"
      ],
      "metadata": {
        "id": "H6_meW7E-QbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img_paths6 = natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(input_dir6, fname)\n",
        "        for fname in os.listdir(input_dir6)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_img_paths6[16:20]"
      ],
      "metadata": {
        "id": "CVtY177p-YvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_mask_paths6 = natsort.natsorted(\n",
        "    [\n",
        "        os.path.join(combined_mask_dir6, fname)\n",
        "        for fname in os.listdir(combined_mask_dir6)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "combined_mask_paths6[16:20]"
      ],
      "metadata": {
        "id": "gZO65flz-ex1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_images = input_img_paths1  + input_img_paths2  + input_img_paths4 + input_img_paths5 + input_img_paths6\n",
        "combined_masks = combined_mask_paths1  + combined_mask_paths2 + combined_mask_paths4 + combined_mask_paths5 + combined_mask_paths6 \n",
        "print(len(combined_masks))\n",
        "print(len(combined_images))"
      ],
      "metadata": {
        "id": "fFc1VBMP-jyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_and_mask = {'image_path':combined_images, 'mask_path':combined_masks}\n",
        "df = pd.DataFrame(image_and_mask)\n",
        "df"
      ],
      "metadata": {
        "id": "Fw2JQK5G-p51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_and_mask = {'image_path':input_test_img_paths, 'mask_path':input_test_mask_paths}\n",
        "df1 = pd.DataFrame(image_and_mask)\n",
        "df1"
      ],
      "metadata": {
        "id": "Bl3gxULF-v6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = [512, 512]\n",
        "\n",
        "def preprocessing(img_path, mak_path):\n",
        "    car_img = tf.io.read_file(img_path) \n",
        "    car_img = tf.image.decode_jpeg(car_img, channels=3)\n",
        "    car_img = tf.image.resize(car_img, IMG_SIZE)\n",
        "    car_img = tf.cast(car_img, tf.float32) / 255.0\n",
        "    \n",
        "    mask_img = tf.io.read_file(mak_path)\n",
        "    mask_img = tf.image.decode_jpeg(mask_img, channels=3)\n",
        "    mask_img = tf.image.resize(mask_img, IMG_SIZE)\n",
        "    mask_img = mask_img[:,:,:1]    \n",
        "    mask_img = tf.math.sign(mask_img)\n",
        "\n",
        "    return car_img, mask_img\n",
        "\n",
        "def create_dataset(df, train = False):\n",
        "    if not train:\n",
        "        ds = tf.data.Dataset.from_tensor_slices((df[\"image_path\"].values, df[\"mask_path\"].values))\n",
        "        ds = ds.map(preprocessing, tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        ds = tf.data.Dataset.from_tensor_slices((df[\"image_path\"].values, df[\"mask_path\"].values))\n",
        "        ds = ds.map(preprocessing, tf.data.AUTOTUNE)\n",
        "        \n",
        "        \n",
        "    return ds"
      ],
      "metadata": {
        "id": "bBE-9i4e-0iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, valid_df = train_test_split(df, random_state=42, test_size=.3)"
      ],
      "metadata": {
        "id": "kt9cODzR-8NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_df))\n",
        "print(len(valid_df))"
      ],
      "metadata": {
        "id": "tu59W5lc_B0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train= create_dataset(df, train = True)\n",
        "valid = create_dataset(df)\n",
        "test = create_dataset(df1)"
      ],
      "metadata": {
        "id": "l8Hs2Xjx_FjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_LENGTH = len(df)\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 1000"
      ],
      "metadata": {
        "id": "MzzrVxeC_JTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "valid_dataset = valid.batch(BATCH_SIZE)\n",
        "test_dataset = test.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "LKJQn3AA_PUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(valid_dataset)"
      ],
      "metadata": {
        "id": "HA5zkO_H_TTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "ind = random.randint(0, 16)\n",
        "for img, msk in valid_dataset:\n",
        "    print(img.shape)\n",
        "    print(msk.shape)\n",
        "    plt.imshow(img[ind])\n",
        "    plt.show()\n",
        "    \n",
        "    plt.imshow(msk[ind,:,:, 0], cmap='gray')\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "d8TGQA7-_XFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model 3 using vgg16 and unet"
      ],
      "metadata": {
        "id": "r8n39GhL_lLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.layers import concatenate\n",
        "from keras.layers.convolutional import Conv2DTranspose\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "yXuEiYAD_eSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "  x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x= Dropout(0.25)(x)\n",
        "\n",
        "  x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "gm3Go1WC_ua-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder connection\n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2,2), strides=2, padding=\"same\")(inputs)\n",
        "    x = concatenate([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x"
      ],
      "metadata": {
        "id": "tIxzbcA9_0r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the pretrained model\n",
        "def build_vgg16_unet(input_shape):\n",
        "  inputs= Input(input_shape)\n",
        "  vgg16 = VGG16(include_top=False, weights= None, input_tensor=inputs, input_shape = [256, 256, 3], pooling = 'max' )\n",
        "\n",
        "  \n",
        "#   skip connection\n",
        "  s1 = vgg16.get_layer(\"block1_conv2\").output   #256\n",
        "  s2 = vgg16.get_layer(\"block2_conv2\").output   #128\n",
        "  s3 = vgg16.get_layer(\"block3_conv3\").output   #64\n",
        "  s4 = vgg16.get_layer(\"block4_conv3\").output   #32\n",
        "#   bridge  layer\n",
        "\n",
        "  b1 = vgg16.get_layer(\"block5_conv3\").output   #16\n",
        "#   decoder block\n",
        "  d1 = decoder_block(b1, s4, 512)#32\n",
        "  d2 = decoder_block(d1, s3, 256)#64\n",
        "  d3 = decoder_block(d2, s2, 128)#128\n",
        "  d4 = decoder_block(d3, s1, 64)#256\n",
        "  outputs = Conv2D(1,1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "  model = Model(inputs,outputs,name='VGG16_Unet')\n",
        "  return model\n",
        "  \n",
        "input_shape = (256, 256, 3)\n",
        "model3 = build_vgg16_unet(input_shape)\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "1O_UTf_v_5a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "\n",
        "# from https://www.kaggle.com/kmader/vgg16-u-net-on-carvana\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1e-5\n",
        "    y_true_f = float(K.flatten(y_true))\n",
        "    y_pred_f = float(K.flatten(y_pred))\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + smooth)/(K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true,y_pred):\n",
        "    smooth = 1e-5\n",
        "    return (1-dice_coef(y_true,y_pred))\n",
        "\n",
        "def IoU(y_true,y_pred):\n",
        "  smooth= 1e-5\n",
        "  y_true_f = float (K.flatten(y_true))\n",
        "  y_pred_f = float (K.flatten(y_pred))\n",
        "  intersection = K.sum(y_true_f*y_pred_f)\n",
        "  result = (intersection + smooth)/(K.sum(y_true_f)+K.sum(y_pred_f)-intersection+ smooth)\n",
        "  return result\n",
        "def IoU_Loss(y_true,y_pred):\n",
        "    smooth= 1e-5\n",
        "    return (1 - IoU(y_true,y_pred))\n",
        "\n",
        "\n",
        "# model.compile(optimizer='adam', loss= [IoU_Loss],metrics=[IoU])"
      ],
      "metadata": {
        "id": "a7ZbSJV__-uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(optimizer= \"Adam\",\n",
        "            #   loss = dice_loss,\n",
        "              loss= IoU_Loss,\n",
        "              metrics=[dice_coef, IoU,'binary_accuracy'])\n",
        "\n",
        "# tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "_9H21vZXAFkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "higIqjdQATFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "oiHEwItXATvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log in to your W&B account\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "3pbWRX7iAYDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "  \"Backbone\": 'Base_line_1',\n",
        "  \"Con2dtranspose_init\": 'he_normal',\n",
        "  \"Decoder_block_type\": \"Conv2DTranspose\",\n",
        "  \"decoder_filters\":(512,256,128,64,32),\n",
        "  'batch_norm': True,\n",
        "  \"Activation\": 'relu',\n",
        "  \"batch_size\": 1, \n",
        "  \"verbose\": 1,\n",
        "  \"initial_epoch\": 0, \n",
        "  \"epochs\": 100,\n",
        "  \"shuffle\": True,\n",
        "  \"Dropout\": 0.25\n",
        "}\n",
        "wandb.init(config = config, project=\"164\", entity=\"claire_nyaketcho_work\")\n",
        "config = wandb.config"
      ],
      "metadata": {
        "id": "Tz4QZ6DOAdDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wandb.keras import WandbCallback\n",
        "callbacks = WandbCallback(\n",
        "                                \n",
        "                                 loss = dice_loss,\n",
        "                               \n",
        "                                log_weights=True,\n",
        "                                log_evaluation=True)"
      ],
      "metadata": {
        "id": "ZmXQTtatAhAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 300\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "\n",
        "model_history = model3.fit(train_dataset, \n",
        "                          epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_data=valid_dataset\n",
        "                          \n",
        "                          )"
      ],
      "metadata": {
        "id": "BiNbxWnFAnSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['loss'], color='b', label=\"Training loss\")\n",
        "plt.plot(model_history.history['val_loss'], color='r', label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f4zjIrRPA27S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['IoU'], color='b', label=\"Training dice coef\")\n",
        "plt.plot(model_history.history['val_IoU'], color='r',label=\"Validation dice coef\")\n",
        "# plt.legend(loc='best', shadow=True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EeLzMjb-A6AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 300\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "\n",
        "model_history = model2.fit(train_dataset, \n",
        "                          epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_data=valid_dataset\n",
        "                          \n",
        "                          )"
      ],
      "metadata": {
        "id": "beKuVTISA-EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['loss'], color='b', label=\"Training loss\")\n",
        "plt.plot(model_history.history['val_loss'], color='r', label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XiMn9cGwBr0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['IoU'], color='b', label=\"Training dice coef\")\n",
        "plt.plot(model_history.history['val_IoU'], color='r',label=\"Validation dice coef\")\n",
        "# plt.legend(loc='best', shadow=True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5GQ47IqjBvpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "n4k-xLwYBy5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save('my_model1.h5')"
      ],
      "metadata": {
        "id": "W1Xx4qE7B33N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "k50D2LajB84d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "m8aH1xb6B__u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.saving import saved_model\n",
        "from keras.models import load_model\n",
        "\n",
        "saved_model = tf.keras.models.load_model('my_model1 (2).h5', compile = False)\n",
        "saved_model.compile(optimizer='adam', \n",
        "              loss=IoU_Loss,\n",
        "               metrics=[IoU,'binary_accuracy'])"
      ],
      "metadata": {
        "id": "8s5sSXlOCFZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "bndxSXMKCJz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# ind = random.randint(0,32)\n",
        "for img, msk in test_dataset:\n",
        "    for i in range(img.shape[0]):\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(title[0])\n",
        "        plt.imshow(img[i])\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(title[1])\n",
        "        plt.imshow(msk[i,:,:,0], cmap='gray')\n",
        "\n",
        "\n",
        "        pred = saved_model.predict(tf.expand_dims(img[i], axis=0))\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(pred[0,:,:,0], cmap='gray')\n",
        "        plt.title(title[2])\n",
        "\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    break\n",
        "\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "xNdxBnxUCOSR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}